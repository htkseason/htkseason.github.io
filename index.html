<!-- saved from url=(0031)https://www.cs.unc.edu/~ezheng/ -->
<html>
<!-- <link rel="stylesheet" href="style.css"> -->
<style>
    body {
        background-color: #ddd;
    }
    
    .main {
        background-color: #eee;
        padding: 30px;
        font-family: "Times";
        font-size: 18px
    }
    
    .intro {
        padding-bottom: 10px;
    }
    
    .proj {}
    
    .proj-table {}
    
    .proj-teaser {
        width: 200px;
        height: 200px;
        padding-left: 10px;
        padding-right: 20px;
    }
    
    .proj-des {
        line-height: 150%
    }
    
    .proj-des-highlight {
        color: red;
    }
</style>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>
        Zhixiang Min
    </title>
</head>

<body>
    <div class="main">
        <div class="intro">
            <h1>Zhixiang Min</h1>
            I am a third-year Ph.D. student at Stevens Institute of Technology, under the supervision of <a href="https://www.cs.stevens.edu/~edunn/">Prof. Enrique Dunn</a>. Before, I received my BSc from Donghua University.
            <p>I am insterested in studying visual odometry, SLAM, multi-view stereo, image-based rendering and learning-based aforementioned tasks.</p>
            <p>Email: zmin1 [at] stevens.edu</p>
        </div>
        <div class="proj">
            <h1>Projects</h1>
            <div class="proj-table">
                <table>
                    <tbody>
                        <!-- icra 2021 -->
                        <tr>
                            <td><img class="proj-teaser" src="./icra2021-teaser.jpg"></td>
                            <td class="proj-des">
                                <b>VOLDOR-SLAM: For the times when feature-based or direct methods are not good enough</b><br>
                                <b>Zhixiang Min</b>, Enrique Dunn <br> (Submitted, under reviewing) <br>
                                <b><span class="proj-des-highlight">Our dense-indirect SLAM solution has achieve 2nd place in
                    both tracks (monocular, stereo) of <a
                      href="https://sites.google.com/view/vislocslamcvpr2020/slam-challenge">CVPR 2020 SLAM
                      Challenge</a>
                    while preserves realtime performance.
                  </span></b>
                            </td>
                        </tr>
                        <!-- cvpr 2020 -->
                        <tr>
                            <td><img class="proj-teaser" src="./cvpr2020-teaser.gif"></td>
                            <td class="proj-des">
                                <b>VOLDOR: Visual Odometry from Log-logistic Dense Optical flow Residuals</b><br>
                                <b>Zhixiang Min</b>, Yiding Yang, Enrique Dunn <br> CVPR 2020 (Oral) <br>
                                <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Min_VOLDOR_Visual_Odometry_From_Log-Logistic_Dense_Optical_Flow_Residuals_CVPR_2020_paper.pdf">[pdf]</a>
                                <a href="https://www.youtube.com/watch?v=wlWjSTiyE4s">[video]</a>
                                <a href="https://github.com/htkseason/VOLDOR">[code]</a>(Patent pending, coming soon)
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>


</body>

</html>